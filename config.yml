path:
  RAW_PATH: "./data/raw/"
  PROCESSED_PATH: "./data/processed/"
  FILES_PATH: "./artifacts/files/"
  TRAIN_IMAGES: "./artifacts/outputs/train_images/"
  TEST_IMAGE: "./artifacts/outputs/test_image/"
  TRAIN_MODELS: "./artifacts/checkpoints/train_models/"
  BEST_MODEL: "./artifacts/checkpoints/best_model/"
  METRICS_PATH: "./artifacts/metrics/"

dataloader:
  image_path: "./data/raw/dataset.zip"
  image_size: 128
  batch_size: 16
  split_size: 0.20

attentionCNN:
  image_channels: 3
  image_size: 128
  nheads: 8
  dropout: 0.3
  num_layers: 2
  activation: "relu"
  bias: True

MLFlow:
  MLFLOW_TRACKING_URI: "https://github.com/atikul-islam-sajib/attentionCNN.git"
  MLFLOW_EXPERIMENT_NAME: "attentionCNN - 1"
  MLFLOW_USERNAME: "atikul-islam-sajib"
  MLFLOW_REPONAME: "attentionCNN"
  MLFLOW_PASSWORD: "74d9f47e6bc7f8a7a170d258186fcdf18a099a991"

Trainer:
  epochs: 500
  lr: 0.0001
  beta1: 0.9
  beta2: 0.999
  momentum: 0.95
  smooth: 1e-4
  alpha: 0.25
  gamma: 2
  step_size: 20
  weight_decay: 0.001
  device: "mps"
  loss: "mse"
  adam: True
  SGD: False
  lr_scheduler: False
  weight_init: False
  l1_regularization: False
  l2_regularization: False
  elasticnet_regularization: False
  mlflow: True
  verbose: True

Tester:
  data: "valid"
  device: "mps"